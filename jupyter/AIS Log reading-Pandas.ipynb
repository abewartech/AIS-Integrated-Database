{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: libais in /opt/conda/lib/python3.7/site-packages (0.17)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from libais) (1.14.0)\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from bokeh) (2.8.1)\n",
      "Requirement already satisfied: pillow>=4.0 in /opt/conda/lib/python3.7/site-packages (from bokeh) (7.0.0)\n",
      "Requirement already satisfied: tornado>=4.3 in /opt/conda/lib/python3.7/site-packages (from bokeh) (6.0.4)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.7/site-packages (from bokeh) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from bokeh) (1.18.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh) (20.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh) (2.11.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh) (5.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=16.8->bokeh) (2.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install libais\n",
    "!{sys.executable} -m pip install bokeh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585223707.080263"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import ais\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask import dataframe as ddf\n",
    "from dask.multiprocessing import get\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "nCores = cpu_count()\n",
    "\n",
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_parse(row):\n",
    "    '''\n",
    "    Parse meta strings. Either single or multiline headers:\n",
    "    s:66,c:1555624754*3E\n",
    "    or \n",
    "    g:1-2-0300,s:66,c:1555624791*46\n",
    "    or \n",
    "    g:2-2-0300*5E\n",
    "    and s:xx multiline messages?\n",
    "    '''\n",
    "    meta, meta_checksum = row['meta'].split(\"*\")\n",
    "    time_found = re.search(r'[0-9]{10}',meta)\n",
    "    \n",
    "    if time_found:\n",
    "        event_time = time_found.group(0)\n",
    "    else:\n",
    "        event_time = None\n",
    "    \n",
    "    row['meta_checksum'] = meta_checksum\n",
    "    row['meta_source'] = meta\n",
    "    row['event_time'] = event_time\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ais_decode_to_dict(row, drop_message_type):\n",
    "    try:\n",
    "        decode_dict = ais.decode(row['payload'],int(row['padding'])) \n",
    "    except Exception as err:\n",
    "        \"try padding to reach 70\"\n",
    "        try:\n",
    "            decode_dict = ais.decode(row['payload'], 12)\n",
    "#             print('It worked!')\n",
    "        except Exception as err:\n",
    "#             print('{1} Still bad: {0}'.format(err, row.name))\n",
    "#             print(row['ais'])            \n",
    "            decode_dict = {}\n",
    "            \n",
    "    if decode_dict.get('id') in drop_message_type:\n",
    "#         print('Dropping unwanted decoded message')\n",
    "        decode_dict = {}\n",
    "    return decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 170 Lines of AIS in the expected format:\n",
    "# infile = 'full_test.log'\n",
    "\n",
    "# 10% of the daily file. Around 70 megs/ 800K messages. \n",
    "#infile = 'decimate_test.log'\n",
    "\n",
    "# Full day:\n",
    "infile = 'TNPA_AIS.log.2019-04-19'\n",
    "\n",
    "ais_sentence = ['packet',\n",
    "  'frag_count',\n",
    "  'frag_num',\n",
    "  'seq_id',\n",
    "  'radio_chan',\n",
    "  'payload',\n",
    "  'padding',\n",
    "  'checksum']\n",
    "\n",
    "first_cols = ['rx_time',\n",
    "          'meta',\n",
    "          'ais',\n",
    "          'meta_checksum',\n",
    "          'meta_source',\n",
    "          'event_time',\n",
    "          'decoded',\n",
    "          'msg_num']\n",
    "\n",
    "meta_cols = ['meta_checksum',\n",
    "            'meta_source',\n",
    "            'event_time']\n",
    "\n",
    "drop_message_type = [7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.1 s, sys: 2.09 s, total: 41.2 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(infile,\n",
    "                 sep=r\": \\\\|\\\\\",\n",
    "                 names=first_cols, \n",
    "                 header=None,\n",
    "                 skiprows=1, \n",
    "                 skip_blank_lines=True,\n",
    "                 engine=\"python\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 2s, sys: 18.8 s, total: 19min 20s\n",
      "Wall time: 19min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df[ais_sentence] = df['ais'].str.split(r',|\\*', expand=True) \n",
    "df = df.apply(lambda x : meta_parse(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# client = Client()\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    " \n",
    "# dask_dataframe = ddf.from_pandas(df, npartitions=2000*nCores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# dask_dataframe = dask_dataframe.apply(lambda x : meta_parse(x), axis=1, meta = dask_dataframe)\n",
    "# dask_dataframe.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# single_dataframe = dask_dataframe[dask_dataframe.frag_count == '1']\n",
    "# single_dataframe.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# multi_ddf = dask_dataframe[dask_dataframe.frag_count == '2']\n",
    "# multi_df = multi_ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate in single and multi-line messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 s, sys: 1.14 s, total: 6.85 s\n",
      "Wall time: 6.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "multi_df = df[df.frag_count == '2']\n",
    "multi_df['prev_payload'] = multi_df['payload'].shift(1)\n",
    "multi_df['prev_event_time'] = multi_df['event_time'].shift(1)\n",
    "multi_df['payload'] = multi_df['prev_payload'] + multi_df['payload']\n",
    "\n",
    "multi_df =  multi_df[multi_df['prev_event_time'].notnull() & multi_df['meta_source'].str.contains('g:2')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 11.9 ms, total: 4.32 s\n",
      "Wall time: 4.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# pass DF to row \n",
    "yy = multi_df.apply(lambda x : ais_decode_to_dict(x, drop_message_type), axis=1)\n",
    "yy_df = pd.DataFrame(yy.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xx =  df.apply(lambda x : ais_decode_to_dict(x,drop_message_type),axis=1) \n",
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df = pd.DataFrame(xx.values.tolist())\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('decoded_single.csv')\n",
    "# yy_df.to_csv('decoded_multi.csv')\n",
    "# multi_df.to_csv('parsed_multi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration to process: 20.68 mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Duration to process: {0} mins\".format(round((end-start)/60,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "- DB Structure Pos vs Voy?   \n",
    "- Combine Single and Multi?     \n",
    "- DB larger when ?\n",
    "\n",
    "\n",
    "# Use Cases (from experience)\n",
    "\n",
    "- History of vessel X?\n",
    "- What vessels are in this area?\n",
    "- get point matches (sar-to-ais and radar-to-ais)\n",
    "- Transhipments (ship-to-ship or ship-to-bilge)\n",
    "- Get names/imo/callsigns from AIS pos report\n",
    "- heatmap agg\n",
    "\n",
    "# Reasearch use cases\n",
    "- various distributions (speeds, nav status, courses) for vessel x for last 7 days (timescale db contiuous agg)\n",
    "- Heatmap agg points\n",
    "- Event based history\n",
    "- API interface (although that's a seperate thing)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
